{
 "metadata": {
  "name": "",
  "signature": "sha256:5223faaecb125313d22e41d914f0b318af69a216c8eb5ff4a808c4d5643c607a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Corpora and Vector Spaces\n",
      "# http://radimrehurek.com/gensim/tut1.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> import logging\n",
      ">>> logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> from gensim import corpora, models, similarities\n",
      ">>>\n",
      ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
      ">>>              \"A survey of user opinion of computer system response time\",\n",
      ">>>              \"The EPS user interface management system\",\n",
      ">>>              \"System and human system engineering testing of EPS\",\n",
      ">>>              \"Relation of user perceived response time to error measurement\",\n",
      ">>>              \"The generation of random binary unordered trees\",\n",
      ">>>              \"The intersection graph of paths in trees\",\n",
      ">>>              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
      ">>>              \"Graph minors A survey\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 16:00:17,551 : INFO : detected Windows; aliasing chunkize to chunkize_serial\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> # remove common words and tokenize\n",
      ">>> stoplist = set('for a of the and to in'.split())\n",
      ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      ">>>          for document in documents]\n",
      ">>>\n",
      ">>> # remove words that appear only once\n",
      ">>> all_tokens = sum(texts, [])\n",
      ">>> tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      ">>> texts = [[word for word in text if word not in tokens_once]\n",
      ">>>          for text in texts]\n",
      ">>>\n",
      ">>> print(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> dictionary = corpora.Dictionary(texts)\n",
      ">>> dictionary.save('/tmp/deerwester.dict') # store the dictionary, for future reference\n",
      ">>> print(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 17:57:19,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 17:57:19,358 : INFO : built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 17:57:19,359 : INFO : saving Dictionary object under /tmp/deerwester.dict, separately None\n"
       ]
      },
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '/tmp/deerwester.dict'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-18ba8bbbb3c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/tmp/deerwester.dict'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# store the dictionary, for future reference\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gensim-0.10.0rc1-py2.7.egg\\gensim\\utils.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname, separately, sep_limit, ignore)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__scipys'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__ignoreds'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mignoreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;31m# restore the attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gensim-0.10.0rc1-py2.7.egg\\gensim\\utils.pyc\u001b[0m in \u001b[0;36mpickle\u001b[1;34m(obj, fname, protocol)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;34m\"\"\"Pickle object `obj` to file `fname`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m         \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gensim-0.10.0rc1-py2.7.egg\\gensim\\utils.pyc\u001b[0m in \u001b[0;36msmart_open\u001b[1;34m(fname, mode)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mgzip\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmake_closing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/tmp/deerwester.dict'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> # collect statistics about all tokens\n",
      ">>> dictionary = corpora.Dictionary(line.lower().split() for line in open('mycorpus.txt'))\n",
      ">>> # remove stop words and words that appear only once\n",
      ">>> stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
      ">>>             if stopword in dictionary.token2id]\n",
      ">>> once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
      ">>> dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      ">>> dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      ">>> print(dictionary)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 21:54:16,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2014-06-03 21:54:16,535 : INFO : built Dictionary(42 unique tokens: [u'and', u'minors', u'generation', u'testing', u'iv']...) from 9 documents (total 69 corpus positions)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}