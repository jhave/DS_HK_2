{
 "metadata": {
  "name": "",
  "signature": "sha256:e216f0d9d955dad2e1fae9d5756a0b40ea1f11566bad7b4d6cb86bb37359449c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "from bs4 import UnicodeDammit\n",
      "\n",
      "import nltk, re, pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIR = '../data/poetryfoundation/poem/'\n",
      "fn = '179391.html'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = BeautifulSoup(open(DIR+fn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# NOTE: the information in the layout such as \n",
      "#     <div style=\"text-indent: -1em; padding-left: 1em;\">\n",
      "#      print(soup.prettify())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#poem\n",
      "# QUESTION How-to clean the poem-text of html so it can be analyzed, but save the layout information for later poem regeneration?\n",
      "poem = soup.find_all(id=\"poem\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#soup.find_all('span', attrs={'class':'author'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# author a href\n",
      "soup.select('span.author a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "[<a href=\"../bio/allen-ginsberg.html\"> Allen  Ginsberg</a>]"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup.select('span.author a')[0].text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "u' Allen  Ginsberg'"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# birthyear\n",
      "soup.select('span.author span.birthyear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "[<span class=\"birthyear\">1926\u20131997</span>]"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup.select('span.author span.birthyear')[0].text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "u'1926\\u20131997'"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "QUESTION: how to remove the non-unicode hyphen from birthyear?\n",
      "I tried:\n",
      "birthyear = UnicodeDammit(soup.select('span.author span.birthyear')[0].text)\n",
      "print birthyear\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# poetic_terms = soup.find(text=\"Poetic Terms\")\n",
      "# FINDS EVERYTHING AFTER.... poetic_terms.find_all_next(\"a\")\n",
      "# EMPTY poetic_terms.find_next_siblings(\"a\")\n",
      "\n",
      "#EMPTY for sect in soup.findAll('section'):\n",
      "    #print(sect)#.find('span.slug'))\n",
      "    \n",
      "# EMPTY soup.findAll('p .section')\n",
      "\n",
      "# ALL PARAS soup.select('p')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LABELS\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Note: not all labels are on each page.\n",
      "Syntax is not easy to parse and separate since they have no id and all same class\n",
      "\n",
      "SCHOOL / PERIOD\n",
      "Poetic Terms\n",
      "Subjects\n",
      "Occasions\n",
      "Poet's Region\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "# labels are all within 'about' div\n",
      "about = soup.find('div', attrs={'class' : 'about'})\n",
      "# nested within their own section\n",
      "ps_about = about.find_all('p', attrs={'class' : 'section'})\n",
      "# get the LABELS that exist\n",
      "for slug in ps_about:\n",
      "    labels = slug.find('span', attrs={'class' : 'slug'})\n",
      "    print(labels.text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Poet\n",
        "SCHOOL / PERIOD\n",
        "Subjects\n",
        "Occasions\n",
        "Poetic Terms\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: separate & stash in a data structure, LIST?\n",
      "# QUESTION: what is best data form to put these labels in so that they can be used by classifier and html corpus is only called-parsed once?\n",
      "for slug in ps_about:\n",
      "    labels = slug.find('span', attrs={'class' : 'slug'})\n",
      "    print(labels.text)\n",
      "    print labels.find_next_siblings()\n",
      "    \n",
      "    \n",
      "    # labels.find_next_sibling(\"a\").text   -- works fine\n",
      "    # labels.find_next_siblings(\"a\").text  -- plural does not work\n",
      "    #if labels.text == 'Poet' or labels.text == 'Poetic Terms':\n",
      "     #   print (labels.find_next(\"a\").text)\n",
      "        \n",
      "    # iteration NOT WORKING\n",
      "    #lbs = labels.find_next_siblings()\n",
      "    #lbs.text\n",
      "    #for lb in lbs:\n",
      "    #   print lb.find('a')#.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Poet\n",
        "[<span>\n",
        "<a href=\"../bio/allen-ginsberg.html\">\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t Allen  Ginsberg</a>\n",
        "</span>, <span class=\"birthyear\">1926\u20131997</span>]\n",
        "SCHOOL / PERIOD\n",
        "[<span class=\"text\"><a href=\"../browse/poets.html#school-period=3\">Beat</a></span>]\n",
        "Subjects\n",
        "[<a href=\"../browse/index.html#subject=6\">Family &amp; Ancestors</a>, <a href=\"../browse/index.html#subject=77\">Relationships</a>, <a href=\"../browse/index.html#subject=71\">Living</a>, <a href=\"../browse/index.html#subject=101\">Sorrow &amp; Grieving</a>, <a href=\"../browse/index.html#subject=23\">Death</a>, <a href=\"../browse/index.html#subject=67\">Religion</a>, <a href=\"../browse/index.html#subject=103\">The Spiritual</a>]\n",
        "Occasions\n",
        "[<a href=\"../browse/index.html#occasion=6\">Funerals</a>]\n",
        "Poetic Terms\n",
        "[<a href=\"../browse/index.html#poetic-terms=21\">Free Verse, </a>, <a href=\"../browse/index.html#poetic-terms=16\">Elegy</a>]\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TODO: year of publication needs to extracted (but parser does not find text)\n",
      "credits = soup.find('div', attrs={'class' : 'credit'})\n",
      "#print credits\n",
      "# Nothing? Why?   credits.find(text = \"Copyright\")\n",
      "# Nothing?        credits.find_all(text=\"\u00a9\")\n",
      "pcred = credits.find(\"p\").text\n",
      "#print pcred\n",
      "\n",
      "#pcred.find(text=\"HarperCollins\")\n",
      "#####  QUESTION: why does preceding not find the text? \n",
      "#####  ANSWER: perhaps? because html is malformed (div is not closed) or ascii unicode decoder has encountered crud\n",
      "# REAL ANSWER: \u00a9 symbol\n",
      "\n",
      "# QUESTION: how-to select year of publication that occurs just after \"Copyright\"?\n",
      "# WORKAROUND\n",
      "pcred[(pcred.find(\"Copyright\")+12):(pcred.find(\"Copyright\")+16)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 223,
       "text": [
        "u'1984'"
       ]
      }
     ],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}