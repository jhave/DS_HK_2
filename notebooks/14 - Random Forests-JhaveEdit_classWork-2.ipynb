{
 "metadata": {
  "name": "",
  "signature": "sha256:6e8b2cf418d3b65b224382eacd50339631377118bfc2a86b0c0a633b071a8ebd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Also with the authorship data, feel free to go back to the base random forest classifer included in sklearn, or see how using adaboost does on guess work."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import numpy as np\n",
      "\n",
      "from pandas import read_csv\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
      "from sklearn import metrics\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn.datasets import make_blobs\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from sklearn.ensemble.weight_boosting import AdaBoostClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authorship = read_csv('http://people.stern.nyu.edu/jsimonof/AnalCatData/Data/Comma_separated/authorship.csv')\n",
      "authors = list(set(authorship.Author.values))\n",
      "le = preprocessing.LabelEncoder()\n",
      "le.fit(authors)\n",
      "authorship['Author_num'] = le.transform(authorship['Author'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Create a random variable (random forests work best with a random variable)\n",
      "authorship['random'] = [random.random() for i in range(841)]\n",
      "\n",
      "#What are some of the stop words we're looking at?\n",
      "features = list(authorship.columns)\n",
      "\n",
      "# take out the response \n",
      "features.remove('Author')\n",
      "features.remove('Author_num')\n",
      "features.remove('BookID')\n",
      "print features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['a', 'all', 'also', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', 'do', 'down', 'even', 'every', 'for', 'from', 'had', 'has', 'have', 'her', 'his', 'if', 'in', 'into', 'is', 'it', 'its', 'may', 'more', 'must', 'my', 'no', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'should', 'so', 'some', 'such', 'than', 'that', 'the', 'their', 'then', 'there', 'things', 'this', 'to', 'up', 'upon', 'was', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'would', 'your', 'random']\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "list"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a test and training set\n",
      "x_train, x_test, y_train, y_test = train_test_split(authorship[features], authorship.Author_num.values, test_size=0.3, random_state=123)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "588"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.arange(x_train.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators =20\n",
      "     \n",
      "for model in (DecisionTreeClassifier(),\n",
      "                  RandomForestClassifier(n_estimators=n_estimators),\n",
      "                  ExtraTreesClassifier(n_estimators=n_estimators),\n",
      "                  AdaBoostClassifier(DecisionTreeClassifier(),\n",
      "                                     n_estimators=n_estimators)):\n",
      "        \n",
      "    \n",
      "        # Standardize\n",
      "        mean = x_train.mean(axis=0)\n",
      "        std = x_train.std(axis=0)\n",
      "        x_train = (x_train - mean) / std\n",
      "\n",
      "        # Train\n",
      "        clf = model.fit(x_train, y_train)\n",
      "\n",
      "        # Get accuracy scores\n",
      "        scores = clf.score(x_test, y_test)\n",
      "        \n",
      "        # Print Confusion Matrix\n",
      "        print metrics.confusion_matrix(clf.predict(x_test), y_test)\n",
      "\n",
      "        # Create a title for each column and the console by using str() and slicing away useless parts of the string\n",
      "        model_title = str(type(model)).split(\".\")[-1][:-2][:-len(\"Classifier\")]\n",
      "        model_details = model_title\n",
      "        if hasattr(model, \"estimators_\"):\n",
      "            model_details += \" with {} estimators\".format(len(model.estimators_))\n",
      "        print model_details + \" has a score of\", scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0   0   0   0]\n",
        " [105  71  14  63]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]]\n",
        "DecisionTree has a score of 0.280632411067\n",
        "[[104  70  14  62]\n",
        " [  1   0   0   0]\n",
        " [  0   0   0   0]\n",
        " [  0   1   0   1]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForest with 20 estimators has a score of 0.415019762846\n",
        "[[105  61   8  61]\n",
        " [  0  10   6   2]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]]\n",
        "ExtraTrees with 20 estimators has a score of 0.454545454545\n",
        "[[105  71  14  63]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AdaBoost with 1 estimators has a score of 0.415019762846\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print Confusion Matrix\n",
      "print metrics.confusion_matrix(clf.predict(x_test), y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[105  71  14  63]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]\n",
        " [  0   0   0   0]]\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}